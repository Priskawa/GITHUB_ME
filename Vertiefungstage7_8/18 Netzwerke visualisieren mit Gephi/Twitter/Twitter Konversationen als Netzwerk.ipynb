{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Konversationen zu einem Thema als Netzwerk untersuchen\n",
    "\n",
    "- Aus Twitter-Daten kann man besonders gut Netzwerke basteln.\n",
    "- Dabei können wir frei definieren,wann eigentlich ein Nutzer mit einem anderen verbunden ist. Die gebräuchlichsten Definitionen sind:\n",
    "    1. Nutzer A retweetet Nutzer B (RT plotti was für ein super tweet)\n",
    "    2. Nutzer A erwähnt Nutzer B (Ich geh das so die Straße lang und seh @plotti)\n",
    "    3. Nutzer A schreibt Nutzer B (@plotti was geht heute)\n",
    "    4. (Nutzer A folgt Nutzer B (Leider um die Struktur einer Konversationen nicht sooo hilfreich. Außerdem muss man über Twarc recht viele User sammeln um diese Information zu erhalten, es geht aber.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten Sammeln über Twarc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/DocNow/twarc\n",
    "- Twarc: A command line tool (and Python library) for archiving Twitter JSON\n",
    "- Sehr praktisch um Tweets zu einem Stichwort zu sammeln. \n",
    "- Man muss eine Twiter app beantragen :(\n",
    "- ```pip install twarc```\n",
    "- ```twarc configure```\n",
    "![Twarc](twarc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twarc\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/f2/2d79badd5fab00826d5fb2a66b0d1923933ef937338edbdbdd01ae3f5181/twarc-1.6.1.tar.gz\n",
      "Collecting pytest (from twarc)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/80/1ac71d332302a89e8637456062186bf397abc5a5b663c1919b73f4d68b1b/pytest-4.0.2-py2.py3-none-any.whl (217kB)\n",
      "\u001b[K    100% |████████████████████████████████| 225kB 455kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /Users/priskawa/.virtualenvs/dataviz/lib/python3.7/site-packages (from twarc) (2.7.3)\n",
      "Collecting requests_oauthlib (from twarc)\n",
      "  Downloading https://files.pythonhosted.org/packages/94/e7/c250d122992e1561690d9c0f7856dadb79d61fd4bdd0e598087dce607f6c/requests_oauthlib-1.0.0-py2.py3-none-any.whl\n",
      "Collecting attrs>=17.4.0 (from pytest->twarc)\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/e1/5f9023cc983f1a628a8c2fd051ad19e76ff7b142a0faf329336f9a62a514/attrs-18.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /Users/priskawa/.virtualenvs/dataviz/lib/python3.7/site-packages (from pytest->twarc) (40.4.3)\n",
      "Collecting atomicwrites>=1.0 (from pytest->twarc)\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/9a/9d878f8d885706e2530402de6417141129a943802c084238914fa6798d97/atomicwrites-1.2.1-py2.py3-none-any.whl\n",
      "Collecting pluggy>=0.7 (from pytest->twarc)\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/e7/017c262070af41fe251401cb0d0e1b7c38f656da634cd0c15604f1f30864/pluggy-0.8.0-py2.py3-none-any.whl\n",
      "Collecting more-itertools>=4.0.0 (from pytest->twarc)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/b1/eace304ef66bd7d3d8b2f78cc374b73ca03bc53664d78151e9df3b3996cc/more_itertools-4.3.0-py3-none-any.whl (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /Users/priskawa/.virtualenvs/dataviz/lib/python3.7/site-packages (from pytest->twarc) (1.10.0)\n",
      "Collecting py>=1.5.0 (from pytest->twarc)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/c7/3da685ef117d42ac8d71af525208759742dd235f8094221fdaafcd3dba8f/py-1.7.0-py2.py3-none-any.whl (83kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 2.8MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting oauthlib>=0.6.2 (from requests_oauthlib->twarc)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/d1/ddd9cfea3e736399b97ded5c2dd62d1322adef4a72d816f1ed1049d6a179/oauthlib-2.1.0-py2.py3-none-any.whl (121kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 560kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /Users/priskawa/.virtualenvs/dataviz/lib/python3.7/site-packages (from requests_oauthlib->twarc) (2.19.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/priskawa/.virtualenvs/dataviz/lib/python3.7/site-packages (from requests>=2.0.0->requests_oauthlib->twarc) (2018.8.24)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /Users/priskawa/.virtualenvs/dataviz/lib/python3.7/site-packages (from requests>=2.0.0->requests_oauthlib->twarc) (2.7)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.0.0->requests_oauthlib->twarc)\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3<1.24,>=1.21.1 in /Users/priskawa/.virtualenvs/dataviz/lib/python3.7/site-packages (from requests>=2.0.0->requests_oauthlib->twarc) (1.23)\n",
      "Building wheels for collected packages: twarc\n",
      "  Running setup.py bdist_wheel for twarc ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/priskawa/Library/Caches/pip/wheels/21/52/21/32b5e3370138a28f7bacb2fc6edbf080b1f77e6fe6a9c3ef6a\n",
      "Successfully built twarc\n",
      "\u001b[31mtextract 1.6.1 has requirement chardet==2.3.0, but you'll have chardet 3.0.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: attrs, atomicwrites, pluggy, more-itertools, py, pytest, oauthlib, requests-oauthlib, twarc, chardet\n",
      "  Found existing installation: chardet 2.3.0\n",
      "    Uninstalling chardet-2.3.0:\n",
      "      Successfully uninstalled chardet-2.3.0\n",
      "Successfully installed atomicwrites-1.2.1 attrs-18.2.0 chardet-3.0.4 more-itertools-4.3.0 oauthlib-2.1.0 pluggy-0.8.0 py-1.7.0 pytest-4.0.2 requests-oauthlib-1.0.0 twarc-1.6.1\n"
     ]
    }
   ],
   "source": [
    "! pip install twarc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten Sammeln "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```twarc search zürich > zürich.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd  \n",
    "import networkx as nx\n",
    "\n",
    "tweetfile = 'zürich.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kanten erzeugen durch Retweets\n",
    "- Personen retweeten sich und deswegen erzeugen wir eine Kante zwischen ihnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Export edges from Retweets\n",
    "\n",
    "fh = open(tweetfile, 'r')\n",
    "\n",
    "userdata = pd.DataFrame(columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count' ))\n",
    "edges = pd.DataFrame(columns=('Source','Target','Time', \"Strength\"))\n",
    "\n",
    "for line in fh:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except:\n",
    "        continue\n",
    "    if 'retweeted_status' not in tweet:\n",
    "        continue\n",
    "    \n",
    "    userdata = userdata.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['user']['screen_name'],\n",
    "                                tweet['user']['created_at'],\n",
    "                                tweet['user']['profile_image_url_https'],\n",
    "                                tweet['user']['followers_count'],\n",
    "                                tweet['user']['friends_count']]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "    userdata = userdata.append(pd.DataFrame([[tweet['retweeted_status']['user']['id_str'],\n",
    "                                tweet['retweeted_status']['user']['screen_name'],\n",
    "                                tweet['retweeted_status']['user']['created_at'],\n",
    "                                tweet['retweeted_status']['user']['profile_image_url_https'],\n",
    "                                tweet['retweeted_status']['user']['followers_count'],\n",
    "                                tweet['retweeted_status']['user']['friends_count']]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)                 \n",
    "    edges = edges.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['retweeted_status']['user']['id_str'],\n",
    "                                str(datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y')),1]]\n",
    "                                , columns=('Source','Target',\"Time\",'Strength')), ignore_index=True)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>profile_image</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18226655</td>\n",
       "      <td>Schnassel</td>\n",
       "      <td>Thu Dec 18 21:59:08 +0000 2008</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/414909368...</td>\n",
       "      <td>42</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>408548113</td>\n",
       "      <td>NZZzuerich</td>\n",
       "      <td>Wed Nov 09 15:30:05 +0000 2011</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/733202507...</td>\n",
       "      <td>3482</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2615811188</td>\n",
       "      <td>adninkari</td>\n",
       "      <td>Thu Jul 10 16:59:03 +0000 2014</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/101147684...</td>\n",
       "      <td>228</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>789605024</td>\n",
       "      <td>EuropaLeague</td>\n",
       "      <td>Wed Aug 29 15:45:49 +0000 2012</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/100616273...</td>\n",
       "      <td>5455310</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2653420078</td>\n",
       "      <td>energyfmsports</td>\n",
       "      <td>Sun Jun 29 14:25:13 +0000 2014</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/106098778...</td>\n",
       "      <td>647</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id           Label                 user_created_at  \\\n",
       "0    18226655       Schnassel  Thu Dec 18 21:59:08 +0000 2008   \n",
       "1   408548113      NZZzuerich  Wed Nov 09 15:30:05 +0000 2011   \n",
       "2  2615811188       adninkari  Thu Jul 10 16:59:03 +0000 2014   \n",
       "3   789605024    EuropaLeague  Wed Aug 29 15:45:49 +0000 2012   \n",
       "4  2653420078  energyfmsports  Sun Jun 29 14:25:13 +0000 2014   \n",
       "\n",
       "                                       profile_image followers_count  \\\n",
       "0  https://pbs.twimg.com/profile_images/414909368...              42   \n",
       "1  https://pbs.twimg.com/profile_images/733202507...            3482   \n",
       "2  https://pbs.twimg.com/profile_images/101147684...             228   \n",
       "3  https://pbs.twimg.com/profile_images/100616273...         5455310   \n",
       "4  https://pbs.twimg.com/profile_images/106098778...             647   \n",
       "\n",
       "  friends_count  \n",
       "0           275  \n",
       "1           215  \n",
       "2           165  \n",
       "3           125  \n",
       "4            50  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Target</th>\n",
       "      <th>Time</th>\n",
       "      <th>Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18226655</td>\n",
       "      <td>408548113</td>\n",
       "      <td>2018-12-14 15:06:08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2615811188</td>\n",
       "      <td>789605024</td>\n",
       "      <td>2018-12-14 15:03:17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2653420078</td>\n",
       "      <td>2715838521</td>\n",
       "      <td>2018-12-14 15:03:14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1048203919548211200</td>\n",
       "      <td>789605024</td>\n",
       "      <td>2018-12-14 14:58:18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>633031016</td>\n",
       "      <td>789605024</td>\n",
       "      <td>2018-12-14 14:57:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Source      Target                 Time Strength\n",
       "0             18226655   408548113  2018-12-14 15:06:08        1\n",
       "1           2615811188   789605024  2018-12-14 15:03:17        1\n",
       "2           2653420078  2715838521  2018-12-14 15:03:14        1\n",
       "3  1048203919548211200   789605024  2018-12-14 14:58:18        1\n",
       "4            633031016   789605024  2018-12-14 14:57:21        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kanten erzeugen durch Mentions\n",
    "- Personen erwähnen sich und deshalb erzeugen wir eine Kante zwischen den Personen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(tweetfile, 'r')\n",
    "\n",
    "userdata = pd.DataFrame(columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count' ))\n",
    "edges = pd.DataFrame(columns=('Source','Target','Strength'))\n",
    "\n",
    "for line in fh:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except:\n",
    "        continue\n",
    "    if len(tweet['entities']['user_mentions']) == 0:\n",
    "        continue\n",
    "    \n",
    "    for mention in tweet['entities']['user_mentions']:\n",
    "        userdata = userdata.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['user']['screen_name'],\n",
    "                                tweet['user']['created_at'],\n",
    "                                tweet['user']['profile_image_url_https'],\n",
    "                                tweet['user']['followers_count'],\n",
    "                                tweet['user']['friends_count']]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "        if len(userdata[userdata['Id'].str.contains(mention['id_str'])]) == 0:\n",
    "            userdata = userdata.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['user']['screen_name'],\n",
    "                                np.nan,\n",
    "                                np.nan,\n",
    "                                np.nan,\n",
    "                                np.nan]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "        edges = edges.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                    mention['id_str'],\n",
    "                                    str(datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y'))]]\n",
    "                                    , columns=('Source','Target','Strength')), ignore_index=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Kanten erzeugen durch gemeinsame Kommunikation\n",
    "- Personen diskutieren miteinander und deshalb erzeugen wir eine Kante zwischen ihnen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fh = open(tweetfile, 'r')\n",
    "\n",
    "userdata = pd.DataFrame(columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count' ))\n",
    "edges = pd.DataFrame(columns=('Source','Target','Strength'))\n",
    "\n",
    "for line in fh:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except:\n",
    "        continue\n",
    "    if tweet['in_reply_to_user_id_str'] is None:\n",
    "        continue\n",
    "\n",
    "    userdata = userdata.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['user']['screen_name'],\n",
    "                                tweet['user']['created_at'],\n",
    "                                tweet['user']['profile_image_url_https'],\n",
    "                                tweet['user']['followers_count'],\n",
    "                                tweet['user']['friends_count']]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "    if len(userdata[userdata['Id'].str.contains(tweet['in_reply_to_user_id_str'])]) == 0:\n",
    "            userdata = userdata.append(pd.DataFrame([[tweet['in_reply_to_user_id_str'],\n",
    "                                tweet['in_reply_to_screen_name'],\n",
    "                                np.nan,\n",
    "                                np.nan,\n",
    "                                np.nan,\n",
    "                                np.nan]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "    edges = edges.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['in_reply_to_user_id_str'],\n",
    "                                str(datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y'))]]\n",
    "                                , columns=('Source','Target','Strength')), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nur jene Kanten behalten die eine gewisse Stärke haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "strengthLevel = 3  # Network connection strength level: the number of times in total each of the tweeters responded to or mentioned the other.\n",
    "                   # If you have 1 as the level, then all tweeters who mentioned or replied to another at least once will be displayed. But if you have 5, only those who have mentioned or responded to a particular tweeter at least 5 times will be displayed, which means that only the strongest bonds are shown.\n",
    "\n",
    "edges2 = edges.groupby(['Source','Target'])['Strength'].count()\n",
    "edges2 = edges2.reset_index()\n",
    "edges2 = edges2[edges2['Strength'] >= strengthLevel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten als Gephi Netzwerk Exportieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_decode(bs):\n",
    "    '''Takes a byte string as param and convert it into a unicode one.\n",
    "First tries UTF8, and fallback to Latin1 if it fails'''\n",
    "    #cr = None\n",
    "    #cr = bs.decode('ascii', 'ignore').encode('ascii')\n",
    "    return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-34175e33ab4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefaultencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0muserdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'followers_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0muserdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reload' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "userdata = userdata.sort_values(['Id','followers_count'], ascending=[True, False])\n",
    "userdata = userdata.drop_duplicates(['Id'], keep='first') \n",
    "\n",
    "ids = edges2['Source'].append(edges2['Target']).to_frame()\n",
    "ids.columns = ['Id']\n",
    "ids = ids.drop_duplicates()\n",
    "\n",
    "nodes = pd.merge(ids, userdata, on='Id', how='left')\n",
    "nodes = nodes.dropna()\n",
    "nodes[\"Label\"] = nodes[\"Label\"].astype(str)\n",
    "nodes[\"Id\"] = nodes[\"Id\"].astype(str)\n",
    "\n",
    "\n",
    "G  = nx.DiGraph(name=\"zürich\")\n",
    "\n",
    "for i, row in nodes.iterrows():\n",
    "    G.add_node(robust_decode(row[\"Id\"]), label=robust_decode(row[\"Label\"]))\n",
    "\n",
    "for i, row in edges2.iterrows():\n",
    "    G.add_edge(robust_decode(row[\"Source\"]),robust_decode(row[\"Target\"]),weight=row[\"Strength\"])\n",
    "\n",
    "nx.write_gexf(G,\"Zürich.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternativ als csv speichern für Kumu.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export nodes from the edges and add node attributes for both Sources and Targets.\n",
    "userdata = userdata.sort_values(['Id','followers_count'], ascending=[True, False])\n",
    "userdata = userdata.drop_duplicates(['Id'], keep='first') \n",
    "\n",
    "ids = edges2['Source'].append(edges2['Target']).to_frame()\n",
    "ids.columns = ['Id']\n",
    "ids = ids.drop_duplicates()\n",
    "\n",
    "nodes = pd.merge(ids, userdata, on='Id', how='left')\n",
    "\n",
    "# change column names for Kumu import (Run this when using Kumu)\n",
    "nodes.columns = ['Id', 'Label', 'Date', 'Image', 'followers_count', 'friends_count']\n",
    "edges2.columns = ['From','To','Strength']\n",
    "\n",
    "# Export nodes and edges to csv files\n",
    "nodes.to_csv('nodes.csv', encoding='utf-8', index=False)\n",
    "edges2.to_csv('edges.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
